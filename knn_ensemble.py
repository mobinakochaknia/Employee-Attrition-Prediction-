# -*- coding: utf-8 -*-
"""KNN-Ensemble.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MWrI_yoaGPLpdFT5Y10Q54PGfatRshQl

<img src="./pic/sharif-main-logo.png" alt="SUT logo" width=345 height=345 align=left class="saturate">


<br>
<font>
<div dir=ltr align=center>
<font color=0F5298 size=7>
    Machine Learning <br>
<font color=2565AE size=5>
    Computer Engineering Department <br>
    Fall 2024<br>
<font color=3C99D size=5>
    Practical Assignment 2 - Unsupervised Learning<br>
<font color=696880 size=4>
    Assignment Supervisor: Niki Sepasian <br>
<font color=696880 size=5>
    Sarina Heshmati
"""

student_number = 401106396
full_name = "mobina kochakia"
assert student_number and full_name is not None, 'please input your information'

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Configure visualizations
sns.set(style="whitegrid")

"""## Overview

In this assignment, you will explore a dataset containing information about employees and use that data to train models capable of predicting whether those employees have left the company (attrited) or not. You will start by exploring the dataset, analyzing its features, and performing necessary preprocessing steps (such as label encoding and scaling). Then, you will build and evaluate implementations of K-Nearest Neighbors (KNN) as well as Random Forest, Bagging, and AdaBoost classifiers. After training and tuning each model, you’ll compare their performance using metrics like accuracy and feature importance to identify the best approach for accurate attrition prediction.

# Load and Explore Dataset (10 points)
"""

import pandas as pd

# Load the dataset
# "Attrition" is our target columm

df = pd.read_csv('dataset.csv')
df.head(5)

"""Explore the dataset and get familiar with its features and statistics. (don't worry about the 'masked values' in our target column. They are simply used to automatically test your model later on.)"""

# TODO: Check the basic structure of the dataset using .info() and .describe()
# Use: df.info() to check data types and missing values
# Use: df.describe() to get summary statistics of numeric features
df.info()
df.describe()
# TODO: Check for any missing values in the dataset
# Use: df.isnull().sum() to find if any column has missing values
print(df.isnull().sum())
# TODO: Explore the target variable (binary classification)
# Use value_counts() to see the distribution of our target (Attrition) column and then visualize it (bar plot).
print(df['Attrition'].value_counts())
plt.figure(figsize=(6, 4))
sns.countplot(x='Attrition', data=df, palette='viridis')
plt.title('Attrition Distribution')
plt.show()
df.head()

"""It is generally better to remove columns with only one unique value from a DataFrame when preparing data for a decision tree. <br>
Such columns do not provide any useful information for splitting the data and can lead to unnecessary complexity in the model. Remove the said columns from the DataFrame.
"""

# TODO Measure and print the number of unique values for each column.
# Check if there are any columns with less than 2 unique values. If so, remove them.

unique_values= {col : df[col].unique() for col in df.columns}
#print(unique_values)
cols_to_drop =[col for col, count in unique_values.items() if len(count) < 2]

df = df.drop(columns=cols_to_drop)

print("\nColumns with less than 2 unique values were dropped.")
print("Updated DataFrame:\n", df.info())

"""Look at the DataFrame and try to gather insight into people's monthly income and things that generally affect this number."""

# Plot (lineplot) the average MonthlyIncome against the YearsAtCompany.
df_copy = df.copy()
avg_income_per_year = df_copy.groupby('YearsAtCompany')['MonthlyIncome'].mean().reset_index()
#Plot the line plot of average MonthlyIncome against YearsAtCompany
plt.figure(figsize=(10, 6))
sns.lineplot(x='YearsAtCompany', y='MonthlyIncome', data=avg_income_per_year, marker='o')
plt.title('Average Monthly Income vs. Years at Company')
plt.xlabel('Years at Company')
plt.ylabel('Average Monthly Income')
plt.grid(True)
plt.show()

# TODO: Then find which departments have the highest and lowest incomes on average.

avg_income_per_department = df_copy.groupby('Department')['MonthlyIncome'].mean().reset_index()

highest_incom_departent = avg_income_per_department.max()
lowest_incom_department = avg_income_per_department.min()

print("Department with the highest average income:", highest_incom_departent)
print("Department with the lowest average income:", lowest_incom_department)

"""# Data Preprocessing (5 points)

Label Encode categorical columns and create a new DataFrame. Then split this data into train and test.
"""

# TODO: Label encode all categorical columns
encoded_df= df.copy()
lable_encoders = {}

for column in encoded_df.select_dtypes(include = ['object']).columns:
    le = LabelEncoder()
    encoded_df[column] = le.fit_transform(encoded_df[column])
    lable_encoders[column] = le

# Split into features and target variable
X = encoded_df.drop(columns=['Attrition'])
y = encoded_df['Attrition']

# TODO: Perform a train-test split using train_test_split() from sklearn
# Split the dataset into training and test sets with a test size of 30%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# TODO: Scale the features using StandardScaler
# Fit the scaler on the training data and transform both the training and test sets

scaler = StandardScaler()
X_train= scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Print the shapes of the resulting datasets to verify the split
print("Training feature set shape:", X_train.shape)
print("Test feature set shape:", X_test.shape)
print("Training target set shape:", y_train.shape)
print("Test target set shape:", y_test.shape)

# TODO Measure and print the number of unique values for each column.
# Check if there are any columns with less than 2 unique values. If so, remove them.
def preprosses(input_name):

  df = pd.read_csv(input_name)

  unique_values= {col : df[col].unique() for col in df.columns}
#print(unique_values)
  cols_to_drop =[col for col, count in unique_values.items() if len(count) < 2]

  df = df.drop(columns=cols_to_drop)

# TODO: Label encode all categorical columns
  lable_encoders = {}

  for column in df.select_dtypes(include = ['object']).columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    lable_encoders[column] = le

  return df, lable_encoders

"""# K-Nearest Neighbors (KNN) Model (15 points)

Implement KNN model from scratch.
"""

from os import pread
import numpy as np
from collections import Counter

class CustomKNN:
    def __init__(self, k):
        """
        Initialize the KNN classifier.

        Parameters:
        - k (int): Number of neighbors to consider.
        """
        # Store the number of neighbors (k)
        self.k = k

    def fit(self, X_train, y_train):
        """
        Fit the KNN classifier to the training data.

        Parameters:
        - X_train (numpy array): Training feature vectors.
        - y_train (numpy array): Training labels.
        """
        # Store training data
        self.X_train = np.array(X_train)
        self.y_train = np.array(y_train)

    def euclidean_distance(self, x1, x2):
        """
        Calculate the Euclidean distance between two data points.

        Parameters:
        - x1 (numpy array): First data point.
        - x2 (numpy array): Second data point.

        Returns:
        - float: Euclidean distance between x1 and x2.
        """
        #Calculate and return the Euclidean distance
        x1_numeric = x1.astype(float)
        x2_numeric = x2.astype(float)

        # Calculate and return the Euclidean distance
        return np.sqrt(np.sum((x1_numeric - x2_numeric) ** 2))

    def predict(self, X_test):
        """
        Predict labels for test data.

        Parameters:
        - X_test (numpy array): Test feature vectors.

        Returns:
        - numpy array: Predicted labels.
        """
        # TODO: Predict label for each test instance and return the array of predictions
        predictions = [ self._predict(x) for x in X_test]
        return np.array(predictions)

    def _predict(self, x):
        """
        Predict label for a single data point.

        Parameters:
        - x (numpy array): Test data point.

        Returns:
        - int: Predicted label.
        """
        # TODO: Compute distances from x to all training points.
        # Find the indices and labels of k nearest neighbors.
        # Perform mafority vote and return the most common label among them.

        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]


        k_indices = np.argsort(distances)[:self.k]

        k_nearest_labels = [self.y_train[i] for i in k_indices]

        most_common = Counter(k_nearest_labels).most_common(1)

        return most_common[0][0]

"""Fit and test your model using different k values and then choose the best one."""

# Optional. You can choose any range of k values that you want.
k_values = [1, 3, 5, 7, 9, 11, 13, 15]
accuracies = []
best_accuracy = 0
best_k = None
for k in k_values:
    y_pred_custom= []

    # TODO: Fit the model using the scaled training data
    # TODO: Make predictions on the scaled test data
    # TODO: Evaluate the model's accuracy for each value of k and choose the best one
    knn = CustomKNN(k)
    knn.fit(X_train, y_train)

    y_pred_custom = knn.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred_custom)
    accuracies.append(accuracy)

    print(f'k: {k} - Accuracy: {accuracy_score(y_test, y_pred_custom)}')


    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_k = k
        Best_custom_model= knn


print(f'The best k value is {best_k} with an accuracy of {best_accuracy:.4f}')

# TODO: Print the accuracy and classification report using sklearn's metrics for your best model
y_pred_best = Best_custom_model.predict(X_test)

# Step 2: Calculate accuracy
knn_accuracy = accuracy_score(y_test, y_pred_best)

# Step 3: Print accuracy
print(f'Accuracy of the best KNN model: {accuracy:.4f}')

# Step 4: Print classification report
report = classification_report(y_test, y_pred_best)
print("Classification Report:")
print(report)

"""Visualize the confusion matrix for KNN predictions"""

# TODO: Create a confusion matrix for KNN predictions
# Use confusion_matrix from sklearn.metrics

# TODO: Visualize the confusion matrix using seaborn's heatmap
# Add annotations and a title for better readability

cm = confusion_matrix(y_test, y_pred_best)

# Step 2: Plotting the confusion matrix using seaborn's heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Attrition', 'Attrition'],
            yticklabels=['No Attrition', 'Attrition'])

# Adding titles and labels
plt.title('Confusion Matrix for KNN Predictions', fontsize=16)
plt.xlabel('Predicted Labels', fontsize=14)
plt.ylabel('True Labels', fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Display the plot
plt.show()

"""## Evaluation (30 points)
In this part, we are going to evaluate your model's performance on another set of unseen data. Load test.csv (this data is already encoded), use your best_custom_model to predict and save the results in a DataFrame called 'result.csv'. The DataFrame should contain one column called 'target' that contains your model's predictions.
"""

# Load test.csv
eval= pd.read_csv('test.csv')
eval_df = eval.copy()

unique_values = {col : eval_df[col].unique() for col in eval_df.columns}
#print(unique_values)
cols_to_drop =[col for col, count in unique_values.items() if len(count) < 2]

eval_df = eval_df.drop(columns=cols_to_drop)

# Label encode all categorical columns
lable_encoders = {}

for column in df.select_dtypes(include = ['object']).columns:
    le = LabelEncoder()
    eval_df[column] = le.fit_transform(eval_df[column])
    lable_encoders[column] = le

# TODO: Use your old scaler to scale the data
# TODO: Predict using your model
df_scaled = scaler.transform(eval_df)
y_pred_eval= Best_custom_model.predict(df_scaled)



"""Save the results in a DataFrame"""

# Save the results as a csv file
result_df= pd.DataFrame()
result_df['target']=pd.Series(y_pred_eval)
result_df.to_csv('result.csv', index= False)

"""# Random Forest Model (12 points)

Implement a random forest model using sklearn.
"""

# TODO: Implement the Random Forest model
rf = RandomForestClassifier(random_state=42)

# TODO: Set up a hyperparameter tuning process for Random Forest using GridSearchCV
# Suggested parameter grid: {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5, 10]}
param_grid_rf = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10]
}
# GridSearchCV with Random Forest
rf_cv = GridSearchCV(rf, param_grid_rf, cv=5)

# TODO: Fit the GridSearchCV on the training data to find the best parameters
# Use rf_cv.fit() with the training data
rf_cv.fit(X_train, y_train)
# TODO: Use the best Random Forest model for predictions on the test data
# Use rf_cv.best_estimator_ and predict()
best_rf_model = rf_cv.best_estimator_
y_pred_rf = best_rf_model.predict(X_test)
# TODO: Print the Random Forest model accuracy and classification report using sklearn's metrics
# Use accuracy_score and classification_report
rf_accuracy = accuracy_score(y_test, y_pred_rf)
report = classification_report(y_test, y_pred_rf)

print(f'Accuracy of the Random Forest model: {rf_accuracy:.4f}')
print("Classification Report:")
print(report)

"""Visualize the confusion matrix for Random Forest predictions"""

# TODO: Create a confusion matrix for Random Forest predictions
# Use confusion_matrix from sklearn.metrics
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)

# TODO: Visualize the confusion matrix using seaborn's heatmap
# Add annotations and a title for better readability

# Step 2: Visualize the confusion matrix using seaborn's heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Attrition', 'Attrition'],
            yticklabels=['No Attrition', 'Attrition'])

# Adding title and labels for better readability
plt.title('Confusion Matrix for Random Forest Predictions')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""A feature importance plot is a visual representation that illustrates the significance of each feature (or variable) in a machine learning model, particularly in the context of supervised learning tasks like classification and regression. Plot the feature importances using a bar plot."""

# Step 1: Get the feature importances from the trained Random Forest model
importances = best_rf_model.feature_importances_

# Step 2: Sort the indices of the importance values in descending order
sorted_indices = np.argsort(importances)[::-1]

# Step 3: Create a DataFrame with feature names and their importance scores
# Assume X_train.columns has the feature names
feature_name = df.columns
feature_importances_df = pd.DataFrame({
    'Feature': feature_name[sorted_indices],
    'Importance': importances[sorted_indices]
})

# Step 4: Plot the feature importances using a bar plot
plt.figure(figsize=(10, 8))
sns.barplot(x='Importance', y='Feature', data=feature_importances_df, palette='viridis')

# Rotate the x-axis labels for readability
plt.title('Feature Importances from Random Forest Model')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.xticks(rotation=45)
plt.tick_params(axis='x', rotation=45)
plt.show()

"""# Bagging with KNN (12 points)"""

bagging_knn = BaggingClassifier(KNeighborsClassifier(n_neighbors=best_k), n_estimators=50, random_state=42)

# Fit the BaggingClassifier on the scaled training data
bagging_knn.fit(X_train, y_train)

# Use the trained Bagging model for predictions on the test data
y_pred_bagging = bagging_knn.predict(X_test)

# Print the Bagging KNN model accuracy and classification report
bagging_accuracy = accuracy_score(y_test, y_pred_bagging)
print(f'Bagging KNN Model Accuracy: {bagging_accuracy:.4f}')
print('Classification Report for Bagging KNN Model:')
print(classification_report(y_test, y_pred_bagging))

"""Visualize the confusion matrix for Baggin KNN predictions"""

# TODO: Create a confusion matrix for Bagging KNN predictions
# Use confusion_matrix from sklearn.metrics
conf_matrix_bagging = confusion_matrix(y_test, y_pred_bagging)
# TODO: Visualize the confusion matrix using seaborn's heatmap
# Add annotations and a title for better readability
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_bagging, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Attrition', 'Attrition'],
            yticklabels=['No Attrition', 'Attrition'])

# Adding title and labels for better readability
plt.title('Confusion Matrix for Random Forest Predictions')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""# AdaBoost Model (12 points)"""

from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report

# Step 1: Initialize the AdaBoost model
adaboost = AdaBoostClassifier(random_state=42)

# Step 2: Define the hyperparameter grid for tuning
param_grid_ada = {
    'n_estimators': [50, 100, 150],
    'learning_rate': [0.01, 0.1, 1.0]
}

# Step 3: Set up GridSearchCV with AdaBoost and the defined parameter grid
adaboost_cv = GridSearchCV(adaboost, param_grid=param_grid_ada, cv=5)

# Step 4: Fit the GridSearchCV on the training data to find the best parameters
adaboost_cv.fit(X_train, y_train)

# Step 5: Use the best AdaBoost model for predictions on the test data
y_pred_ada = adaboost_cv.best_estimator_.predict(X_test)

# Step 6: Print the AdaBoost model accuracy and classification report
ada_accuracy = accuracy_score(y_test, y_pred_ada)
print(f'AdaBoost Model Accuracy: {ada_accuracy:.4f}')
print('Classification Report for AdaBoost Model:')
print(classification_report(y_test, y_pred_ada))

"""Visualize the confusion matrix for AdaBoost predictions"""

# TODO: Create a confusion matrix for AdaBoost predictions
# Use confusion_matrix from sklearn.metrics
conf_matrix_ada = confusion_matrix(y_test, y_pred_ada)
# TODO: Visualize the confusion matrix using seaborn's heatmap
# Add annotations and a title for better readability
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_ada, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Attrition', 'Attrition'],
            yticklabels=['No Attrition', 'Attrition'])

# Adding title and labels for better readability
plt.title('Confusion Matrix for Random Forest Predictions')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""# Model Comparison (4 points)"""

# TODO: Compare model accuracies for KNN, Random Forest, Bagging KNN, and AdaBoost
# Create a DataFrame with model names and their respective accuracies
model_names = ['KNN', 'Random Forest', 'Bagging KNN', 'AdaBoost']
model_accuracies = [knn_accuracy, rf_accuracy, bagging_accuracy, ada_accuracy]

# Create a DataFrame
accuracy_df = pd.DataFrame({
    'Model': model_names,
    'Accuracy': model_accuracies
})

print(accuracy_df)
# TODO: Visualize the model comparison using a line plot
# Use seaborn's lineplot to plot model names vs. accuracies

sns.set(style='whitegrid')

# Create a line plot
plt.figure(figsize=(10, 6))
sns.lineplot(data=accuracy_df, x='Model', y='Accuracy', marker='o')

# Add labels and title
plt.title('Model Accuracy Comparison')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.ylim(0, 1)  # Adjust y-axis limits if needed
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.grid(True)

# Show the plot
plt.show()